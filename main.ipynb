{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ba65b7",
   "metadata": {},
   "source": [
    "## COSC522: Final Project - Catifier\n",
    "### Cameron Adkins, Purnachandra Anirudh Gajjala, Gabriel Abeyie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ee6a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Numpy.\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "# Need plots.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pandas.\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning toolkit.\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Scipy for fft's and the like.\n",
    "import scipy as sc\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy import stats\n",
    "\n",
    "# Seaborn for plots.\n",
    "import seaborn as sns\n",
    "\n",
    "# IPython for basic visual output types.\n",
    "import IPython\n",
    "\n",
    "# Imbalanced learn for rebalancing.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Standard Python libs.\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import xml.etree.ElementTree as et\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Pillow.\n",
    "import PIL as pil\n",
    "\n",
    "# Tensorflow\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.keras.datasets import fashion_mnist\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.layers import Conv2D, Flatten, Dense, AveragePooling2D, GlobalAveragePooling2D,Dropout\n",
    "#from tensorflow.keras.applications.resnet import ResNet50\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# For images\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553e7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utility functions.\n",
    "\n",
    "def image_load(filename):\n",
    "    loader = pil.Image.open(filename);\n",
    "    ret = loader.copy();\n",
    "    loader.close();\n",
    "    \n",
    "    return ret;\n",
    "\n",
    "def image_resize(image, new_width):\n",
    "    new_height = int(new_width * (image.height / image.width));\n",
    "    \n",
    "    return image.resize((new_width, new_height), pil.Image.Resampling.LANCZOS);\n",
    "\n",
    "def trimap_to_mask(trimap, include_border = True):\n",
    "    trimap_data = trimap.getdata();\n",
    "    \n",
    "    mask_data = np.zeros((trimap.height, trimap.width), dtype=np.uint8);\n",
    "    \n",
    "    for x in range(0, trimap.width):\n",
    "        for y in range(0, trimap.height):\n",
    "            idx = x + (y * trimap.width);\n",
    "            tri = trimap_data[idx];\n",
    "            \n",
    "            if (tri == 1 or (include_border == True and tri == 3)):\n",
    "                mask_data[y, x] = 255;\n",
    "            else:\n",
    "                mask_data[y, x] = 0;\n",
    "                \n",
    "    mask = pil.Image.fromarray(mask_data);\n",
    "    \n",
    "    return mask;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982e566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Class definitions.\n",
    "\n",
    "@dataclass\n",
    "class Point:\n",
    "    x: int;\n",
    "    y: int;\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    ll: Point;\n",
    "    lr: Point;\n",
    "    ul: Point;\n",
    "    ur: Point;\n",
    "\n",
    "class CatBreedSample:\n",
    "    def __init__(self, label, image_file, mask_file = None, bb_file = None):\n",
    "        self.label = label;\n",
    "        \n",
    "        self.image_file = image_file;\n",
    "        self.mask_file  = mask_file;\n",
    "        self.bb_file    = bb_file;\n",
    "        \n",
    "        # Load the image\n",
    "        self.image = image_load(self.image_file);\n",
    "\n",
    "        # Composite if a mask is available.\n",
    "        if (self.mask_file):\n",
    "            self.mask = trimap_to_mask(image_load(self.mask_file), False);\n",
    "            \n",
    "            background = pil.Image.new(\"RGB\", self.mask.size, 0);\n",
    "            self.masked_image = pil.Image.composite(self.image, background, self.mask);\n",
    "        else:\n",
    "            self.mask = None;\n",
    "            self.masked_image = None;\n",
    "            \n",
    "        # Get a bounding box.\n",
    "        if (self.bb_file):\n",
    "            tree = et.parse(self.bb_file);\n",
    "            root = tree.getroot();\n",
    "\n",
    "            xmin = int(root.findall(\"./object/bndbox/xmin\")[0].text);\n",
    "            xmax = int(root.findall(\"./object/bndbox/xmax\")[0].text);\n",
    "            ymin = int(root.findall(\"./object/bndbox/ymin\")[0].text);\n",
    "            ymax = int(root.findall(\"./object/bndbox/ymax\")[0].text);\n",
    "\n",
    "            self.bb = BoundingBox(0, 0, 0, 0);\n",
    "            \n",
    "            self.bb.ll = Point(xmin, ymin);\n",
    "            self.bb.lr = Point(xmax, ymin);\n",
    "            self.bb.ul = Point(xmin, ymax);\n",
    "            self.bb.ur = Point(xmax, ymax);\n",
    "            \n",
    "            if (self.masked_image):\n",
    "                self.bounded_image = self.masked_image.crop((xmin, ymin, xmax, ymax));\n",
    "            else:\n",
    "                self.bounded_image = self.image.crop((xmin, ymin, xmax, ymax));\n",
    "\n",
    "        else:\n",
    "            self.bb = None;\n",
    "            self.bounded_image = None;\n",
    "\n",
    "        self.image = image_resize(self.image, 256);\n",
    "        self.masked_image = image_resize(self.masked_image, 256);\n",
    "        self.bounded_image = image_resize(self.bounded_image, 256);\n",
    "\n",
    "    def display(self):\n",
    "        print(\"Image:\", self.image_file);\n",
    "        print(\"Label:\", self.label);\n",
    "        \n",
    "        display(self.image);\n",
    "        \n",
    "        if (self.mask):\n",
    "            display(self.masked_image);\n",
    "            \n",
    "        if (self.bb):\n",
    "            display(self.bounded_image);\n",
    "            \n",
    "    def features(self):\n",
    "        fv = [];\n",
    "        \n",
    "        # Determine eye positions.\n",
    "        \n",
    "        # Determine ear positions.\n",
    "        \n",
    "        # Determine total pixel count of the four colors.\n",
    "        \n",
    "        fv.append(1);\n",
    "        \n",
    "        return fv;\n",
    "    \n",
    "    def segmentation_regionbased(self):\n",
    "        gray = rgb2gray(np.array(self.bounded_image));\n",
    "        #plt.imshow(gray, cmap = 'gray')\n",
    "        \n",
    "        gray_r = gray.reshape(gray.shape[0]*gray.shape[1])\n",
    "        \n",
    "        for i in range(gray_r.shape[0]):\n",
    "            \n",
    "            if gray_r[i] > gray_r.mean():\n",
    "                \n",
    "                gray_r[i] = 1\n",
    "\n",
    "            else:\n",
    "                \n",
    "                gray_r[i] = 0\n",
    "\n",
    "        gray = gray_r.reshape(gray.shape[0],gray.shape[1])\n",
    "        plt.figure();\n",
    "        plt.imshow(gray, cmap='gray')\n",
    "        \n",
    "        # The darker region (black) represents the background and the brighter (white) region is the foreground. We can define multiple thresholds as well to detect multiple objects:\n",
    "\n",
    "        # gray_r = gray.reshape(gray.shape[0]*gray.shape[1])\n",
    "\n",
    "        #for i in range(gray_r.shape[0]):\n",
    "            #if gray_r[i] > gray_r.mean():\n",
    "                #gray_r[i] = 3\n",
    "            #elif gray_r[i] > 0.5:\n",
    "                #gray_r[i] = 2\n",
    "            #elif gray_r[i] > 0.25:\n",
    "                #gray_r[i] = 1\n",
    "            #else:\n",
    "                #gray_r[i] = 0\n",
    "\n",
    "        #gray = gray_r.reshape(gray.shape[0],gray.shape[1])\n",
    "        #plt.imshow(gray, cmap='gray')\n",
    "            \n",
    "    def segmentation_edgebased(self):\n",
    "        gray = rgb2gray(np.array(self.bounded_image));\n",
    "                \n",
    "        #plt.figure();\n",
    "        #plt.imshow(gray, cmap='gray');\n",
    "\n",
    "        # defining the sobel filters\n",
    "\n",
    "        # [\n",
    "        #  [ 1  2  1]\n",
    "        #  [ 0  0  0]\n",
    "        #  [-1 -2 -1]\n",
    "        # ] \n",
    "        # is a kernel for detecting horizontal edges\n",
    "\n",
    "        # [\n",
    "        #  [-1  0  1]\n",
    "        #  [-2  0  2]\n",
    "        #  [-1  0  1]\n",
    "        # ] \n",
    "        # is a kernel for detecting vertical edges\n",
    "\n",
    "        sobel_horizontal = np.array([np.array([1, 2, 1]), np.array([0, 0, 0]), np.array([-1, -2, -1])])\n",
    "        print('Kernel for detecting horizontal edges:\\n', sobel_horizontal)\n",
    "\n",
    "        sobel_vertical = np.array([np.array([-1, 0, 1]), np.array([-2, 0, 2]), np.array([-1, 0, 1])])\n",
    "        print('Kernel for detecting vertical edges:\\n', sobel_vertical)\n",
    "\n",
    "        out_h = ndimage.convolve(gray, sobel_horizontal, mode='reflect')\n",
    "        out_v = ndimage.convolve(gray, sobel_vertical, mode='reflect')\n",
    "\n",
    "        # here mode determines how the input array is extended when the filter overlaps a border.\n",
    "\n",
    "        plt.figure();\n",
    "        plt.imshow(out_h, cmap='gray')\n",
    "        plt.imshow(out_v, cmap='gray')\n",
    "\n",
    "        # Here, we are able to identify the horizontal as well as the vertical edges. There is one more type of filter that can detect both horizontal and vertical edges at the same time. This is called the laplace operator:\n",
    "\n",
    "        # [\n",
    "        #  [1  1  1]\n",
    "        #  [1 -8  1]\n",
    "        #  [1  1  1]\n",
    "        # ]\n",
    "\n",
    "        kernel_laplace = np.array([np.array([1, 1, 1]), np.array([1, -8, 1]), np.array([1, 1, 1])])\n",
    "        print(\"Laplacian kernel:\\n\", kernel_laplace)\n",
    "        \n",
    "        out_l = ndimage.convolve(gray, kernel_laplace, mode='reflect')\n",
    "        plt.figure();\n",
    "        plt.imshow(out_l, cmap='gray')\n",
    "\n",
    "    def segmentation_colorclustering(self):\n",
    "        # According to wikipedia the R, G, and B components of an object’s color in a digital image are all correlated with the amount of light hitting the object, \n",
    "        # and therefore with each other, image descriptions in terms of those components make object discrimination difficult. \n",
    "        # Descriptions in terms of hue/lightness/chroma or hue/lightness/saturation are often more relevant. So, we need to convert our image from RGB Colours Space to HSV to work ahead.\n",
    "\n",
    "        cv2img = np.array(self.masked_image);\n",
    "\n",
    "        vectorized = np.float32(cv2img.reshape((-1,3)))\n",
    "        vectorized.shape\n",
    "\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)\n",
    "\n",
    "        K = 4\n",
    "        attempts=10\n",
    "        ret, label, center = cv2.kmeans(vectorized, K, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)\n",
    "\n",
    "        center = np.uint8(center)\n",
    "        res = center[label.flatten()]\n",
    "        result_image = res.reshape((cv2img.shape))\n",
    "\n",
    "        # result_image is the output result. Lets see how the image looks after k-means clustering\n",
    "\n",
    "        figure_size = 15\n",
    "        plt.figure(figsize=(figure_size, figure_size))\n",
    "        plt.subplot(2,3,1),plt.imshow(cv2img)\n",
    "        plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(2,3,2),plt.imshow(result_image)\n",
    "        plt.title('Segmented Image when K = %i' % K), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    def haarcascade_classifier(self):\n",
    "        cv2img  = np.array(self.image);\n",
    "        cv2gray = cv2.cvtColor(cv2img, cv2.COLOR_RGB2GRAY);\n",
    "        \n",
    "        cascade = cv2.CascadeClassifier(\"pretrained/haarcascade_frontalcatface.xml\");\n",
    "        \n",
    "        bounding_rects = cascade.detectMultiScale(cv2gray, scaleFactor = 1.3, minNeighbors = 1, minSize = (25, 25));\n",
    "        \n",
    "        print(bounding_rects);\n",
    "        \n",
    "        for (x, y, w, h) in bounding_rects:\n",
    "            cv2.rectangle(cv2gray, (x, y), (x + w, y + h), (0, 0, 255), 2);\n",
    "            \n",
    "        plt.figure();\n",
    "        plt.imshow(cv2gray, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fce611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_sample = CatBreedSample(\n",
    "    \"Abyssinian\", \n",
    "    \"/home/cva/catifier/training_data/Abyssinian/Abyssinian_110.jpg\",\n",
    "    \"/home/cva/catifier/training_data/Abyssinian/Abyssinian_110_mask.png\",\n",
    "    \"/home/cva/catifier/training_data/Abyssinian/Abyssinian_110_bb.xml\"\n",
    ")\n",
    "\n",
    "test_sample.display();\n",
    "test_sample.segmentation_regionbased();\n",
    "test_sample.segmentation_edgebased();\n",
    "test_sample.segmentation_colorclustering();\n",
    "test_sample.haarcascade_classifier();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611a746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load everything.\n",
    "def load_samples(samples_dir):\n",
    "    class_dirs = glob.glob(samples_dir + \"/*\")\n",
    "\n",
    "    samples = [];\n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        label = os.path.basename(class_dir);\n",
    "        class_dir_glob = glob.glob(class_dir + \"/*.jpg\");\n",
    "    \n",
    "        print(\"Reading files for label '\" + label + \"'\");\n",
    "    \n",
    "        for sample_image in class_dir_glob:\n",
    "            basename  = os.path.splitext(sample_image)[0];\n",
    "            mask_file = basename + \"_mask.png\";\n",
    "            bb_file   = basename + \"_bb.xml\";\n",
    "            \n",
    "            if (not os.path.exists(mask_file)):\n",
    "                mask_file = None;\n",
    "                \n",
    "            if (not os.path.exists(bb_file)):\n",
    "                continue;\n",
    "                #bb_file = None;\n",
    "            \n",
    "            print(\n",
    "                len(samples), \n",
    "                \":\", \n",
    "                os.path.basename(sample_image), \n",
    "                \"\\t(mask:\", \n",
    "                (mask_file != None), \n",
    "                \"| bb:\", \n",
    "                (bb_file != None), \n",
    "                \")\"\n",
    "            );\n",
    "            \n",
    "            sample = CatBreedSample(label, sample_image, mask_file, bb_file);\n",
    "            samples.append(sample);\n",
    "\n",
    "    return samples;\n",
    "\n",
    "PWD = os.getcwd();\n",
    "TRAINING_DATA = PWD + \"/training_data\";\n",
    "samples = load_samples(TRAINING_DATA);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a8128",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_id = 120;\n",
    "samples[sample_id].display();\n",
    "samples[sample_id].segmentation_regionbased();\n",
    "samples[sample_id].segmentation_edgebased();\n",
    "samples[sample_id].segmentation_colorclustering();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the model.\n",
    "fv = [];\n",
    "labels = [];\n",
    "\n",
    "for sample in samples:\n",
    "    fv.append(sample.features());\n",
    "    labels.append(sample.label);\n",
    "    \n",
    "# Rebalance.\n",
    "oversampler = SMOTE();\n",
    "(fv, labels) = oversampler.fit_resample(fv, labels);\n",
    "\n",
    "# Scale.\n",
    "scaler = RobustScaler();\n",
    "fv = scaler.fit_transform(fv);\n",
    "    \n",
    "# Split the data.\n",
    "x_train, x_test, y_train, y_test = train_test_split(fv, labels, test_size = 0.30, random_state = 64);\n",
    "\n",
    "# Train.\n",
    "dt = RandomForestClassifier();\n",
    "dt.fit(x_train, y_train);\n",
    "\n",
    "# Testing the model.\n",
    "cv_scores = cross_val_score(dt, x_train, y_train, cv = 10);\n",
    "\n",
    "print('Average Cross Validation Score from Training:', cv_scores.mean(), sep = '\\n', end = '\\n\\n\\n');\n",
    "\n",
    "y_pred = dt.predict(x_test);\n",
    "cm = confusion_matrix(y_test, y_pred);\n",
    "cr = classification_report(y_test, y_pred);\n",
    "\n",
    "print('Confusion Matrix:', cm, sep = '\\n', end = '\\n\\n\\n');\n",
    "print('Missing classifications (if any):', set(y_test) - set(y_pred));\n",
    "print('Test Statistics:', cr, sep = '\\n', end = '\\n\\n\\n');\n",
    "print('Testing Accuracy:', accuracy_score(y_test, y_pred));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
